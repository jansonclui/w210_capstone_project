{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest\n",
    "import itertools, collections\n",
    "import re\n",
    "import operator\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#read in data to clean and separate into training and test set\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "good = []\n",
    "bad = []\n",
    "score = []\n",
    "tags = []\n",
    "lines = []\n",
    "\n",
    "#1 is good\n",
    "#0 is not\n",
    "\n",
    "#based on the distribution of scores, I rounded up the mean to 95 and used that to determine good and bad\n",
    "#turns out the distribution between good and bad is pretty even.\n",
    "for line in open('naomit_review_scores_final').readlines():\n",
    "    data = line.split('\\t')\n",
    "    clean_score = re.sub(\"[^0-9]\", \"\", data[1])\n",
    "    desc = data[0]\n",
    "    if clean_score != '' and int(clean_score) <= 100 and int(clean_score) > 0:\n",
    "        if int(clean_score) >= 95:\n",
    "            for each in desc.lower().split('.'):\n",
    "                if each != ' ' and each != '':\n",
    "                    good.append(re.sub('[^A-Za-z]', ' ', each))\n",
    "                    #pre_lines.append((re.sub('[^A-Za-z]', ' ', each), 'good'))\n",
    "                    lines.append(re.sub('[^A-Za-z]', ' ', each),)\n",
    "                    score.append(int(clean_score))\n",
    "                    tags.append(int(1))\n",
    "           \n",
    "        elif int(clean_score) < 95:\n",
    "            for each in desc.lower().split('.'):\n",
    "                if each != ' ' and each != '':\n",
    "                    #pre_lines.append((re.sub('[^A-Za-z]', ' ', each), 'bad'))\n",
    "                    lines.append(re.sub('[^A-Za-z]', ' ', each))\n",
    "                    bad.append(re.sub('[^A-Za-z]', ' ', each))\n",
    "                    score.append(int(clean_score))\n",
    "                    tags.append(int(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318902\n",
      "861171\n",
      "2180073\n",
      "2180073\n",
      "2180073\n",
      "super clean and convenient to public transit\n",
      "96\n",
      "great location  very accessible to public transport  coffee shops  the mission and castro  the apartment was very comfortable and well equipped\n",
      "96\n",
      " it was lovely having a garden courtyard and we even saw hummingbirds  however  it was difficult to reach our host to confirm arrangements and how to get in to the apartment\n",
      "96\n",
      " we didn t receive a confirmation email or welcome info and compared to other airbnb stays it was sub standard client service\n",
      "96\n",
      " it meant we were waiting on doorstep wondering if it was all going to be ok\n",
      "96\n",
      " it was  but would have preferred not having to wonder\n",
      "96\n",
      " the apartment was under the living area of the house and with two boisterous boys we were woken up early by running and thumping above us on what seemed rice paper ceilings\n",
      "96\n",
      " despite that we enjoyed our time in san fransisco but would stay somewhere else next time\n",
      "96\n",
      "my husband and i had a great stay here for three nights of work meetings   some weekend fun\n",
      "96\n",
      " great location near duboce park and muni\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print len(good)\n",
    "print len(bad)\n",
    "\n",
    "#lines = good + bad\n",
    "print len(lines)\n",
    "print len(score)\n",
    "print len(tags)\n",
    "for x in range(0,10):\n",
    "    print good[x]\n",
    "    print score[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090036\n",
      "1090036\n",
      "super clean and convenient to public transit\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "training = lines[:len(lines)/2]\n",
    "testing = lines[len(lines)/2:]\n",
    "\n",
    "tag_train = tags[:len(tags)/2]\n",
    "tag_test = tags[len(tags)/2:]\n",
    "\n",
    "print len(training)\n",
    "print len(tag_train)\n",
    "print lines[0]\n",
    "print tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " great location accessible public transport coffee shops mission castro apartment comfortable well equipped\n"
     ]
    }
   ],
   "source": [
    "#removing stop words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "no_stop_words = []\n",
    "         \n",
    "for each in lines:\n",
    "    sentence = \"\"\n",
    "    words = word_tokenize(each)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            sentence = sentence + \" \" + w\n",
    "\n",
    "    no_stop_words.append(sentence)\n",
    "    \n",
    "print no_stop_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LR with all words\n",
    "feature_extraction = TfidfVectorizer()\n",
    "X = feature_extraction.fit_transform(lines)\n",
    "y = tags\n",
    "X_train_0 = X[:len(lines)/2]\n",
    "X_test_0 = X[len(lines)/2:]\n",
    "Y_train_0 = y[:len(tags)/2]\n",
    "Y_test_0 = y[len(tags)/2:]\n",
    "\n",
    "# Train model\n",
    "clf_0 = LogisticRegression().fit(X_train_0, Y_train_0)\n",
    "# Predict on training set\n",
    "pred_y_0 = clf_0.predict(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635001380687\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#without taking out stop words\n",
    "print( accuracy_score(pred_y_0, Y_test_0) )\n",
    "print( np.unique( pred_y_0 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LR without stop words\n",
    "feature_extraction = TfidfVectorizer()\n",
    "X = feature_extraction.fit_transform(no_stop_words)\n",
    "y = tags\n",
    "X_train_1 = X[:len(no_stop_words)/2]\n",
    "X_test_1 = X[len(no_stop_words)/2:]\n",
    "Y_train_1 = y[:len(tags)/2]\n",
    "Y_test_1 = y[len(tags)/2:]\n",
    "\n",
    "\n",
    "# Train model\n",
    "clf_1 = LogisticRegression().fit(X_train_1, Y_train_1)\n",
    "# Predict on training set\n",
    "pred_y_1 = clf_1.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632011573919\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#after stop words\n",
    "print( accuracy_score(pred_y_1, Y_test_1) )\n",
    "print( np.unique( pred_y_1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318902\n",
      "1318902\n"
     ]
    }
   ],
   "source": [
    "#######UPSAMPLING \"BAD\" CATEGORY TO MATCH GOOD#########\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "lines_majority = good\n",
    "lines_minority = bad\n",
    " \n",
    "# Upsample minority class\n",
    "bad_upsampled = resample(lines_minority, \n",
    "                         replace=True,     # sample with replacement\n",
    "                         n_samples=1318902,    # to match majority class\n",
    "                         random_state=123) # reproducible results\n",
    " \n",
    "    \n",
    "# Combine majority class with upsampled minority class\n",
    "print len(bad_upsampled)\n",
    "print len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318902\n",
      "2637804\n",
      "2637804\n",
      "2637804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for each in good:\n",
    "    new_list.append((each, int(1)))\n",
    "\n",
    "print len(new_list)\n",
    "bad_upsampled = list(bad_upsampled)\n",
    "for each in bad_upsampled:\n",
    "    new_list.append((each, int(0)))\n",
    "\n",
    "print len(new_list)\n",
    "\n",
    "\n",
    "\n",
    "shuffle(new_list)\n",
    "\n",
    "new_lines = []\n",
    "new_tags = []\n",
    "\n",
    "for each in new_list:\n",
    "    new_lines.append(each[0])\n",
    "    new_tags.append(each[1])\n",
    "                     \n",
    "                     \n",
    "print len(new_lines)\n",
    "print len(new_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer()\n",
    "X = feature_extraction.fit_transform(new_lines)\n",
    "y = new_tags\n",
    "\n",
    "X_train_2 = X[:len(new_lines)/2]\n",
    "X_test_2 = X[len(new_lines)/2:]\n",
    "Y_train_2 = new_tags[:len(new_tags)/2]\n",
    "Y_test_2 = new_tags[len(new_tags)/2:]\n",
    "\n",
    "\n",
    "# Train model\n",
    "clf_2 = LogisticRegression().fit(X_train_2, Y_train_2)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651537415214\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print( accuracy_score(pred_y_2, Y_test_2) )\n",
    "print( np.unique( pred_y_2 ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
